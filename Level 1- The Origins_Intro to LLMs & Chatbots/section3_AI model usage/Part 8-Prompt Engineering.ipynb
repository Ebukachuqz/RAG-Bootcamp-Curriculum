{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181a5fb6-1a3f-4857-a30e-08b42798df86",
   "metadata": {},
   "source": [
    "# **Section 3: AI Model Usage in Practice**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008133d-d01b-4c14-b668-200d42fd7bca",
   "metadata": {},
   "source": [
    "## **Part 8: Prompt Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25ba60-be9b-41a7-8b45-4fef38f753b0",
   "metadata": {},
   "source": [
    "## **What is Prompt Engineering?**\n",
    "\n",
    "---\n",
    "\n",
    "When using AI models like ChatGPT or other LLMs, the **prompt** is simply the **input** you give the model.\n",
    "\n",
    "**Prompt Engineering** is the practice of:\n",
    "‚úîÔ∏è Carefully crafting your prompts\n",
    "‚úîÔ∏è Structuring them to guide the model\n",
    "‚úîÔ∏è Using techniques to improve the quality, reliability, and relevance of the outputs\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Prompts Matter**\n",
    "\n",
    "AI models don't understand human intentions the way people do. They only see text and predict the next token based on patterns in their training data.\n",
    "\n",
    "That means:\n",
    "‚úîÔ∏è A vague prompt = Unclear, random, or irrelevant output\n",
    "‚úîÔ∏è A well-crafted prompt = Precise, useful, and coherent output\n",
    "\n",
    "**In short:** The model is only as good as the instructions you give it.\n",
    "\n",
    "---\n",
    "\n",
    "## **Illustration**\n",
    "\n",
    "Imagine giving instructions to a new intern:\n",
    "\n",
    "‚úîÔ∏è If you say:\n",
    "‚ÄúHelp me with this.‚Äù\n",
    "‚Äî They‚Äôll be confused. Help you how? With what?\n",
    "\n",
    "‚úîÔ∏è But if you say:\n",
    "‚ÄúPlease summarize this document into 3 key points for our meeting.‚Äù\n",
    "‚Äî They‚Äôll know exactly what to do.\n",
    "\n",
    "AI models behave similarly. They need clear, structured prompts.\n",
    "\n",
    "---\n",
    "\n",
    "## **Basic Prompt Structures**\n",
    "\n",
    "Here are common ways to structure prompts effectively:\n",
    "\n",
    "### 1. **Instruction-Only Prompt**\n",
    "\n",
    "Directly tell the model what to do.\n",
    "\n",
    "**Example:**\n",
    "‚ÄúSummarize the following text.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Instruction + Context Prompt**\n",
    "\n",
    "Give both the task and relevant background.\n",
    "\n",
    "**Example:**\n",
    "‚ÄúYou are an expert science teacher. Summarize the following biology text for high school students.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Few-Shot Prompting**\n",
    "\n",
    "Provide examples of the task you want the model to perform.\n",
    "\n",
    "**Example:**\n",
    "‚ÄúConvert the following sentences to formal language:\n",
    "\n",
    "* Casual: 'Hey, what‚Äôs up?' ‚Üí Formal: 'Good afternoon, how may I assist you?'\n",
    "* Casual: 'Can you help me out?' ‚Üí Formal: 'Would you kindly assist me?'\n",
    "\n",
    "Now convert: 'Gimme a sec.'‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## **System, User, Assistant Roles (Chat Models)**\n",
    "\n",
    "When working with chat-based models like GPT-4 Chat, prompts are structured with roles:\n",
    "\n",
    "| Role          | Purpose                               |\n",
    "| ------------- | ------------------------------------- |\n",
    "| **System**    | Defines model behavior or personality |\n",
    "| **User**      | The human's input or question         |\n",
    "| **Assistant** | The model's generated response        |\n",
    "\n",
    "**Example Prompt Structure:**\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a polite customer support assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"My order hasn't arrived. What should I do?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Techniques for Better Prompts**\n",
    "\n",
    "| Technique                    | Description                    | Example                                  |\n",
    "| ---------------------------- | ------------------------------ | ---------------------------------------- |\n",
    "| **Explicit Instructions**    | Clearly state what you expect  | ‚ÄúList 3 pros and cons of electric cars.‚Äù |\n",
    "| **Define Role or Persona**   | Make the model adopt a role    | ‚ÄúYou are a professional recruiter.‚Äù      |\n",
    "| **Specify Output Format**    | Guide response structure       | ‚ÄúRespond in bullet points.‚Äù              |\n",
    "| **Set Constraints**          | Limit length, tone, or style   | ‚ÄúWrite in 2 sentences, in formal tone.‚Äù  |\n",
    "| **Give Examples (Few-Shot)** | Provide examples to learn from | ‚ÄúTranslate: 'Hola' ‚Üí 'Hello'...‚Äù         |\n",
    "\n",
    "---\n",
    "\n",
    "## **Advanced Prompting Concepts**\n",
    "\n",
    "### 1. **Chain-of-Thought Prompting**\n",
    "\n",
    "Encourage the model to reason step by step.\n",
    "\n",
    "**Example:**\n",
    "‚ÄúExplain your reasoning step by step before answering.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Zero-Shot Prompting**\n",
    "\n",
    "No examples provided ‚Äî purely rely on clear instructions.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Few-Shot Prompting**\n",
    "\n",
    "Provide 1-5 examples for the model to imitate the pattern.\n",
    "\n",
    "---\n",
    "\n",
    "## **Prompt Experimentation is Normal**\n",
    "\n",
    "Even experienced AI engineers test multiple versions of a prompt to:\n",
    "‚úîÔ∏è Reduce irrelevant outputs\n",
    "‚úîÔ∏è Handle edge cases\n",
    "‚úîÔ∏è Improve accuracy\n",
    "\n",
    "Prompt Engineering is often an **iterative process**, not a one-shot solution.\n",
    "\n",
    "---\n",
    "\n",
    "## **üíª Code Example: Prompt Engineering with OpenAI**\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"your_api_key_here\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a professional career advisor.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I'm struggling to choose a tech career path. Can you help?\"}\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Prompt Engineering in Real-World Applications**\n",
    "\n",
    "‚úîÔ∏è Chatbots providing customer support\n",
    "‚úîÔ∏è AI writing assistants generating articles\n",
    "‚úîÔ∏è Code generation tools like GitHub Copilot\n",
    "‚úîÔ∏è AI tutors explaining complex concepts\n",
    "‚úîÔ∏è AI search tools retrieving accurate information\n",
    "\n",
    "**In all these cases**, effective prompts dramatically improve AI usefulness and reliability.\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary: Prompt Engineering**\n",
    "\n",
    "‚úÖ Good prompts = better AI responses\n",
    "‚úÖ Clear instructions, role definition, output format all help\n",
    "‚úÖ Few-shot examples guide the model's behavior\n",
    "‚úÖ It's an iterative process ‚Äî experimentation is key\n",
    "‚úÖ Mastering prompts = unlocking the full potential of AI tools\n",
    "\n",
    "---\n",
    "\n",
    "**Next Up:** We'll explore Limitations and Considerations when using AI in practice ‚Äî including bias, hallucination, and safety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9b6bf-ede7-4214-a17b-b9cddaf71557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
