{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6d37b2-9c96-4f81-bda7-866c22d37717",
   "metadata": {},
   "source": [
    "# Part 1: What is Langchain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9ac5f-19e2-47d3-82db-adc2108583f0",
   "metadata": {},
   "source": [
    "When you first start working with AI models like ChatGPT or Gemini, things feel simple enough. You send a prompt, you get a response. It feels like magic.\n",
    "\n",
    "For example, using Google's Gemini model with the Langchain integration looks like this:\n",
    "\n",
    "```python\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "response = llm.invoke(\"Tell me a fun fact about space.\")\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "The model gives you a fun fact. Great! But as soon as you try to build something more than a toy demoâ€”maybe a chatbot, a document Q\\&A system, or an AI assistantâ€”the cracks start to show.\n",
    "\n",
    "You realize that:\n",
    "\n",
    "* Your prompts get messy and hard to maintain\n",
    "* You need structured, reliable outputs, not just free-flowing text\n",
    "* You want multi-step reasoning or logic, but managing that manually is painful\n",
    "* Your code becomes scattered, fragile, and hard to scale\n",
    "\n",
    "This is exactly the problem Langchain solves.\n",
    "\n",
    "---\n",
    "\n",
    "## So, What is Langchain?\n",
    "\n",
    "Langchain is a **framework that helps you structure AI-powered applications**, especially those built around Large Language Models (LLMs).\n",
    "\n",
    "It doesn't replace your LLM (like Gemini or GPT-4), it wraps around itâ€”bringing order, clarity, and powerful tools for:\n",
    "\n",
    "âœ… Prompt management\n",
    "âœ… Multi-step reasoning (chains)\n",
    "âœ… Output parsing and structured results\n",
    "âœ… Composing reusable, maintainable AI logic\n",
    "\n",
    "Think of Langchain as the missing architectural layer between raw LLMs and real-world AI applications.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Would You Need a Framework?\n",
    "\n",
    "Letâ€™s pause for a relatable analogy.\n",
    "\n",
    "Imagine trying to build a house using only raw materialsâ€”bricks, cement, woodâ€”with no blueprints, no tools, no organized process. Technically possible, but painful, error-prone, and messy.\n",
    "\n",
    "Langchain gives you the **blueprints and tools** to build AI apps in a structured, maintainable way.\n",
    "\n",
    "---\n",
    "\n",
    "## What Does Langchain Actually Do?\n",
    "\n",
    "At its core, Langchain provides:\n",
    "\n",
    "* A standard way to build prompts and messages\n",
    "* Tools to chain multiple steps of logic together\n",
    "* Clean handling of LLM outputsâ€”whether plain text or structured formats\n",
    "* Flexibility to swap LLM providers if needed\n",
    "\n",
    "All while keeping your code organized and scalable.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Illustration: From Chaos to Structure\n",
    "\n",
    "Let me show you how raw LLM interaction compares to Langchain-powered structure.\n",
    "\n",
    "### The Raw Way: Manually Building Prompts\n",
    "\n",
    "```python\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "# Manually crafting the prompt\n",
    "prompt = \"You are a helpful assistant.\\nHuman: What is a fun fact about the ocean?\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "For a simple one-liner, this works. But imagine building dynamic prompts with variables, conditions, or reusable partsâ€”it quickly gets ugly.\n",
    "\n",
    "---\n",
    "\n",
    "### The Langchain Way: Clean and Reusable\n",
    "\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Step 1: Define your LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "\n",
    "# Step 2: Define a prompt template with placeholders\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Step 3: Insert your dynamic variable\n",
    "messages = prompt.format_messages(question=\"What is a fun fact about the ocean?\")\n",
    "\n",
    "# Step 4: Send to LLM\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "```\n",
    "\n",
    "Notice:\n",
    "\n",
    "âœ”ï¸ Prompts are clean, reusable, and readable\n",
    "âœ”ï¸ Variables like `{question}` make it dynamic\n",
    "âœ”ï¸ You separate logic from contentâ€”just like good software design\n",
    "\n",
    "---\n",
    "\n",
    "## Beyond Prompts: Chains and More\n",
    "\n",
    "Langchain isnâ€™t just about prompts. It introduces **Chains**, which let you link together:\n",
    "\n",
    "* Prompt generation\n",
    "* LLM invocation\n",
    "* Output handling\n",
    "\n",
    "All in one neat, maintainable flow.\n",
    "\n",
    "Hereâ€™s a sneak peek (weâ€™ll explore this in detail later):\n",
    "\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = chain.invoke({\"question\": \"What's the capital of France?\"})\n",
    "print(result[\"text\"])\n",
    "```\n",
    "\n",
    "Instead of stitching everything manually, the **Chain** handles the full flow for you.\n",
    "\n",
    "---\n",
    "\n",
    "## Where Does Langchain Fit in the AI Development Picture?\n",
    "\n",
    "Picture this:\n",
    "\n",
    "ðŸ› ï¸ You have your LLM â€” Gemini, GPT, Claude, etc.\n",
    "ðŸ› ï¸ You need to build a real application â€” chatbot, assistant, RAG system, etc.\n",
    "ðŸ› ï¸ You want maintainable, scalable code â€” not a tangle of messy prompt strings\n",
    "\n",
    "Langchain sits perfectly in between:\n",
    "\n",
    "```\n",
    "Your App Logic  --->  Langchain  --->  LLM (Gemini, GPT, etc.)\n",
    "```\n",
    "\n",
    "It gives structure to how your app talks to the LLM, handles responses, and composes logic.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Langchain is your **AI app orchestrator**. It:\n",
    "\n",
    "âœ… Brings structure to how you interact with LLMs\n",
    "âœ… Simplifies prompts, outputs, and multi-step logic\n",
    "âœ… Makes your AI projects more maintainable and production-ready\n",
    "\n",
    "Without it, building anything beyond basic demos with LLMs becomes painful. With it, your AI development feels like software engineeringâ€”not duct-tape hacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbc202-7665-4fcd-9910-a30c0e11ab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
